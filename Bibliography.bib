
@misc{yao_react_2023,
	title = {{ReAct}: Synergizing Reasoning and Acting in Language Models},
	url = {http://arxiv.org/abs/2210.03629},
	doi = {10.48550/arXiv.2210.03629},
	shorttitle = {{ReAct}},
	abstract = {While large language models ({LLMs}) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of {LLMs} to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named {ReAct}, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering ({HotpotQA}) and fact verification (Fever), {ReAct} overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia {API}, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks ({ALFWorld} and {WebShop}), {ReAct} outperforms imitation and reinforcement learning methods by an absolute success rate of 34\% and 10\% respectively, while being prompted with only one or two in-context examples. Project site with code: https://react-lm.github.io},
	number = {{arXiv}:2210.03629},
	publisher = {{arXiv}},
	author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
	urldate = {2025-01-18},
	date = {2023-03-10},
	eprinttype = {arxiv},
	eprint = {2210.03629 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/felix/Zotero/storage/QNZ89KYR/Yao et al. - 2023 - ReAct Synergizing Reasoning and Acting in Languag.pdf:application/pdf;Snapshot:/Users/felix/Zotero/storage/5ZWF4ZJC/2210.html:text/html},
}

@article{wang_survey_2024,
	title = {A survey on large language model based autonomous agents},
	volume = {18},
	issn = {2095-2236},
	url = {https://doi.org/10.1007/s11704-024-40231-1},
	doi = {10.1007/s11704-024-40231-1},
	abstract = {Autonomous agents have long been a research focus in academic and industry communities. Previous research often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of Web knowledge, large language models ({LLMs}) have shown potential in human-level intelligence, leading to a surge in research on {LLM}-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of {LLM}-based autonomous agents from a holistic perspective. We first discuss the construction of {LLM}-based autonomous agents, proposing a unified framework that encompasses much of previous work. Then, we present a overview of the diverse applications of {LLM}-based autonomous agents in social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for {LLM}-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field.},
	pages = {186345},
	number = {6},
	journaltitle = {Frontiers of Computer Science},
	shortjournal = {Front. Comput. Sci.},
	author = {Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and Zhao, Wayne Xin and Wei, Zhewei and Wen, Jirong},
	urldate = {2025-01-24},
	date = {2024-03-22},
	langid = {english},
	keywords = {Artificial Intelligence, autonomous agent, human-level intelligence, large language model},
	file = {Full Text PDF:/Users/felix/Zotero/storage/4TWAXB63/Wang et al. - 2024 - A survey on large language model based autonomous .pdf:application/pdf},
}

@inproceedings{ruan_tptu_2023,
	title = {{TPTU}: Task Planning and Tool Usage of Large Language Model-based {AI} Agents},
	url = {https://openreview.net/forum?id=GrkgKtOjaH},
	shorttitle = {{TPTU}},
	abstract = {With recent advancements in natural language processing, Large Language Models ({LLMs}) have emerged as powerful tools for various real-world applications. Despite their prowess, the intrinsic generative abilities of {LLMs} may prove insufficient for handling complex tasks which necessitate a combination of task planning and the usage of external tools. In this paper, we first propose a structured framework tailored for {LLM}-based {AI} Agents and discuss the crucial capabilities necessary for tackling intricate problems. Within this framework, we design two distinct types of agents (i.e., one-step agent and sequential agent) to execute the inference process. Subsequently, we instantiate the framework using various {LLMs} and evaluate their Task Planning and Tool Usage ({TPTU}) abilities on typical tasks. By highlighting key findings and challenges, our goal is to provide a helpful resource for researchers and practitioners to leverage the power of {LLMs} in their {AI} applications. Our study emphasizes the substantial potential of these models, while also identifying areas that need more investigation and improvement.},
	eventtitle = {{NeurIPS} 2023 Foundation Models for Decision Making Workshop},
	author = {Ruan, Jingqing and Chen, {YiHong} and Zhang, Bin and Xu, Zhiwei and Bao, Tianpeng and Qing, Du Guo and Shiwei, Shi and Mao, Hangyu and Li, Ziyue and Zeng, Xingyu and Zhao, Rui},
	urldate = {2025-01-24},
	date = {2023-11-08},
	langid = {english},
	file = {Full Text PDF:/Users/felix/Zotero/storage/P7Y8UZCN/Ruan et al. - 2023 - TPTU Task Planning and Tool Usage of Large Langua.pdf:application/pdf},
}

@article{schick_toolformer_2023,
	title = {Toolformer: Language Models Can Teach Themselves to Use Tools},
	volume = {36},
	url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/d842425e4bf79ba039352da0f658a906-Abstract-Conference.html},
	shorttitle = {Toolformer},
	pages = {68539--68551},
	journaltitle = {Advances in Neural Information Processing Systems},
	author = {Schick, Timo and Dwivedi-Yu, Jane and Dessi, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
	urldate = {2025-01-24},
	date = {2023-12-15},
	langid = {english},
	file = {Full Text PDF:/Users/felix/Zotero/storage/K69LUHUM/Schick et al. - 2023 - Toolformer Language Models Can Teach Themselves t.pdf:application/pdf},
}

@misc{lu_turn_2024,
	title = {Turn Every Application into an Agent: Towards Efficient Human-Agent-Computer Interaction with {API}-First {LLM}-Based Agents},
	url = {http://arxiv.org/abs/2409.17140},
	doi = {10.48550/arXiv.2409.17140},
	shorttitle = {Turn Every Application into an Agent},
	abstract = {Multimodal large language models ({MLLMs}) have enabled {LLM}-based agents to directly interact with application user interfaces ({UIs}), enhancing agents' performance in complex tasks. However, these agents often suffer from high latency and low reliability due to the extensive sequential {UI} interactions. To address this issue, we propose {AXIS}, a novel {LLM}-based agents framework prioritize actions through application programming interfaces ({APIs}) over {UI} actions. This framework also facilitates the creation and expansion of {APIs} through automated exploration of applications. Our experiments on Office Word demonstrate that {AXIS} reduces task completion time by 65\%-70\% and cognitive workload by 38\%-53\%, while maintaining accuracy of 97\%-98\% compare to humans. Our work contributes to a new human-agent-computer interaction ({HACI}) framework and a fresh {UI} design principle for application providers in the era of {LLMs}. It also explores the possibility of turning every applications into agents, paving the way towards an agent-centric operating system (Agent {OS}).},
	number = {{arXiv}:2409.17140},
	publisher = {{arXiv}},
	author = {Lu, Junting and Zhang, Zhiyang and Yang, Fangkai and Zhang, Jue and Wang, Lu and Du, Chao and Lin, Qingwei and Rajmohan, Saravan and Zhang, Dongmei and Zhang, Qi},
	urldate = {2025-01-24},
	date = {2024-09-25},
	eprinttype = {arxiv},
	eprint = {2409.17140 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/Users/felix/Zotero/storage/GU28N4RH/Lu et al. - 2024 - Turn Every Application into an Agent Towards Effi.pdf:application/pdf;Snapshot:/Users/felix/Zotero/storage/9BJ5DBQ6/2409.html:text/html},
}

@inproceedings{li_api-bank_2023,
	location = {Singapore},
	title = {{API}-Bank: A Comprehensive Benchmark for Tool-Augmented {LLMs}},
	url = {https://aclanthology.org/2023.emnlp-main.187/},
	doi = {10.18653/v1/2023.emnlp-main.187},
	shorttitle = {{API}-Bank},
	abstract = {Recent research has demonstrated that Large Language Models ({LLMs}) can enhance their capabilities by utilizing external tools. However, three pivotal questions remain unanswered: (1) How effective are current {LLMs} in utilizing tools? (2) How can we enhance {LLMs}' ability to utilize tools? (3) What obstacles need to be overcome to leverage tools? To address these questions, we introduce {API}-Bank, a groundbreaking benchmark, specifically designed for tool-augmented {LLMs}. For the first question, we develop a runnable evaluation system consisting of 73 {API} tools. We annotate 314 tool-use dialogues with 753 {API} calls to assess the existing {LLMs}' capabilities in planning, retrieving, and calling {APIs}. For the second question, we construct a comprehensive training set containing 1,888 tool-use dialogues from 2,138 {APIs} spanning 1,000 distinct domains. Using this dataset, we train Lynx, a tool-augmented {LLM} initialized from Alpaca. Experimental results demonstrate that {GPT}-3.5 exhibits improved tool utilization compared to {GPT}-3, while {GPT}-4 excels in planning. However, there is still significant potential for further improvement. Moreover, Lynx surpasses Alpaca`s tool utilization performance by more than 26 pts and approaches the effectiveness of {GPT}-3.5. Through error analysis, we highlight the key challenges for future research in this field to answer the third question.},
	eventtitle = {{EMNLP} 2023},
	pages = {3102--3116},
	booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
	publisher = {Association for Computational Linguistics},
	author = {Li, Minghao and Zhao, Yingxiu and Yu, Bowen and Song, Feifan and Li, Hangyu and Yu, Haiyang and Li, Zhoujun and Huang, Fei and Li, Yongbin},
	editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
	urldate = {2025-01-24},
	date = {2023-12},
	file = {Full Text PDF:/Users/felix/Zotero/storage/VHWS25XK/Li et al. - 2023 - API-Bank A Comprehensive Benchmark for Tool-Augme.pdf:application/pdf},
}

@misc{openai_gpt-4_2024,
	title = {{GPT}-4 Technical Report},
	url = {http://arxiv.org/abs/2303.08774},
	doi = {10.48550/arXiv.2303.08774},
	abstract = {We report the development of {GPT}-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, {GPT}-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. {GPT}-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of {GPT}-4's performance based on models trained with no more than 1/1,000th the compute of {GPT}-4.},
	number = {{arXiv}:2303.08774},
	publisher = {{arXiv}},
	author = {{OpenAI} and Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and Avila, Red and Babuschkin, Igor and Balaji, Suchir and Balcom, Valerie and Baltescu, Paul and Bao, Haiming and Bavarian, Mohammad and Belgum, Jeff and Bello, Irwan and Berdine, Jake and Bernadett-Shapiro, Gabriel and Berner, Christopher and Bogdonoff, Lenny and Boiko, Oleg and Boyd, Madelaine and Brakman, Anna-Luisa and Brockman, Greg and Brooks, Tim and Brundage, Miles and Button, Kevin and Cai, Trevor and Campbell, Rosie and Cann, Andrew and Carey, Brittany and Carlson, Chelsea and Carmichael, Rory and Chan, Brooke and Chang, Che and Chantzis, Fotis and Chen, Derek and Chen, Sully and Chen, Ruby and Chen, Jason and Chen, Mark and Chess, Ben and Cho, Chester and Chu, Casey and Chung, Hyung Won and Cummings, Dave and Currier, Jeremiah and Dai, Yunxing and Decareaux, Cory and Degry, Thomas and Deutsch, Noah and Deville, Damien and Dhar, Arka and Dohan, David and Dowling, Steve and Dunning, Sheila and Ecoffet, Adrien and Eleti, Atty and Eloundou, Tyna and Farhi, David and Fedus, Liam and Felix, Niko and Fishman, Simón Posada and Forte, Juston and Fulford, Isabella and Gao, Leo and Georges, Elie and Gibson, Christian and Goel, Vik and Gogineni, Tarun and Goh, Gabriel and Gontijo-Lopes, Rapha and Gordon, Jonathan and Grafstein, Morgan and Gray, Scott and Greene, Ryan and Gross, Joshua and Gu, Shixiang Shane and Guo, Yufei and Hallacy, Chris and Han, Jesse and Harris, Jeff and He, Yuchen and Heaton, Mike and Heidecke, Johannes and Hesse, Chris and Hickey, Alan and Hickey, Wade and Hoeschele, Peter and Houghton, Brandon and Hsu, Kenny and Hu, Shengli and Hu, Xin and Huizinga, Joost and Jain, Shantanu and Jain, Shawn and Jang, Joanne and Jiang, Angela and Jiang, Roger and Jin, Haozhun and Jin, Denny and Jomoto, Shino and Jonn, Billie and Jun, Heewoo and Kaftan, Tomer and Kaiser, Łukasz and Kamali, Ali and Kanitscheider, Ingmar and Keskar, Nitish Shirish and Khan, Tabarak and Kilpatrick, Logan and Kim, Jong Wook and Kim, Christina and Kim, Yongjik and Kirchner, Jan Hendrik and Kiros, Jamie and Knight, Matt and Kokotajlo, Daniel and Kondraciuk, Łukasz and Kondrich, Andrew and Konstantinidis, Aris and Kosic, Kyle and Krueger, Gretchen and Kuo, Vishal and Lampe, Michael and Lan, Ikai and Lee, Teddy and Leike, Jan and Leung, Jade and Levy, Daniel and Li, Chak Ming and Lim, Rachel and Lin, Molly and Lin, Stephanie and Litwin, Mateusz and Lopez, Theresa and Lowe, Ryan and Lue, Patricia and Makanju, Anna and Malfacini, Kim and Manning, Sam and Markov, Todor and Markovski, Yaniv and Martin, Bianca and Mayer, Katie and Mayne, Andrew and {McGrew}, Bob and {McKinney}, Scott Mayer and {McLeavey}, Christine and {McMillan}, Paul and {McNeil}, Jake and Medina, David and Mehta, Aalok and Menick, Jacob and Metz, Luke and Mishchenko, Andrey and Mishkin, Pamela and Monaco, Vinnie and Morikawa, Evan and Mossing, Daniel and Mu, Tong and Murati, Mira and Murk, Oleg and Mély, David and Nair, Ashvin and Nakano, Reiichiro and Nayak, Rajeev and Neelakantan, Arvind and Ngo, Richard and Noh, Hyeonwoo and Ouyang, Long and O'Keefe, Cullen and Pachocki, Jakub and Paino, Alex and Palermo, Joe and Pantuliano, Ashley and Parascandolo, Giambattista and Parish, Joel and Parparita, Emy and Passos, Alex and Pavlov, Mikhail and Peng, Andrew and Perelman, Adam and Peres, Filipe de Avila Belbute and Petrov, Michael and Pinto, Henrique Ponde de Oliveira and Michael and Pokorny and Pokrass, Michelle and Pong, Vitchyr H. and Powell, Tolly and Power, Alethea and Power, Boris and Proehl, Elizabeth and Puri, Raul and Radford, Alec and Rae, Jack and Ramesh, Aditya and Raymond, Cameron and Real, Francis and Rimbach, Kendra and Ross, Carl and Rotsted, Bob and Roussez, Henri and Ryder, Nick and Saltarelli, Mario and Sanders, Ted and Santurkar, Shibani and Sastry, Girish and Schmidt, Heather and Schnurr, David and Schulman, John and Selsam, Daniel and Sheppard, Kyla and Sherbakov, Toki and Shieh, Jessica and Shoker, Sarah and Shyam, Pranav and Sidor, Szymon and Sigler, Eric and Simens, Maddie and Sitkin, Jordan and Slama, Katarina and Sohl, Ian and Sokolowsky, Benjamin and Song, Yang and Staudacher, Natalie and Such, Felipe Petroski and Summers, Natalie and Sutskever, Ilya and Tang, Jie and Tezak, Nikolas and Thompson, Madeleine B. and Tillet, Phil and Tootoonchian, Amin and Tseng, Elizabeth and Tuggle, Preston and Turley, Nick and Tworek, Jerry and Uribe, Juan Felipe Cerón and Vallone, Andrea and Vijayvergiya, Arun and Voss, Chelsea and Wainwright, Carroll and Wang, Justin Jay and Wang, Alvin and Wang, Ben and Ward, Jonathan and Wei, Jason and Weinmann, C. J. and Welihinda, Akila and Welinder, Peter and Weng, Jiayi and Weng, Lilian and Wiethoff, Matt and Willner, Dave and Winter, Clemens and Wolrich, Samuel and Wong, Hannah and Workman, Lauren and Wu, Sherwin and Wu, Jeff and Wu, Michael and Xiao, Kai and Xu, Tao and Yoo, Sarah and Yu, Kevin and Yuan, Qiming and Zaremba, Wojciech and Zellers, Rowan and Zhang, Chong and Zhang, Marvin and Zhao, Shengjia and Zheng, Tianhao and Zhuang, Juntang and Zhuk, William and Zoph, Barret},
	urldate = {2025-01-24},
	date = {2024-03-04},
	eprinttype = {arxiv},
	eprint = {2303.08774 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/felix/Zotero/storage/652B78AM/OpenAI et al. - 2024 - GPT-4 Technical Report.pdf:application/pdf;Snapshot:/Users/felix/Zotero/storage/UD4PS8GS/2303.html:text/html},
}

@article{brooke_sus_1995,
	title = {{SUS} - A quick and dirty usability scale},
	abstract = {Usability does not exist in any absolute sense; it can only be defined with reference to particular contexts. This, in turn, means that there are no absolute measures of usability, since, if the usability of an artefact is defined by the context in which that artefact is used, measures of usability must of necessity be defined by that context too. Despite this, there is a need for broad general measures which can be used to compare usability across a range of contexts. In addition, there is a need for “quick and dirty” methods to allow low cost assessments of usability in industrial systems evaluation. This chapter describes the System Usability Scale ({SUS}) a reliable, low-cost usability scale that can be used for global assessments of systems usability.},
	author = {Brooke, John},
	date = {1995-11},
	langid = {english},
	file = {Brooke - SUS - A quick and dirty usability scale.pdf:/Users/felix/Zotero/storage/LI2N7U64/Brooke - SUS - A quick and dirty usability scale.pdf:application/pdf},
}
